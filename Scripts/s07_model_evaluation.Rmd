---
title: "Model evaluation"
author: "Helena Edlund"
date: "2019-01-08"
output: 
  html_document
params:
  print_results: FALSE
---

```{r setup, include=F}
###################################################
# s07_model_evaluation.Rmd
# Description: Graphical and summary evaluation of base models
# Dependencies: s07_model_execute.R 
###################################################

# Settings to knit in top directory:
# Everything after this chunk works with paths relative top level
library(rprojroot)
knitr::opts_knit$set(root.dir=find_root(has_file("OpenProject.Rproj"))) 
knitr::opts_chunk$set(echo=F)

# Note: R markdown opens a new R session, your global environment is not available.
```

```{r environmentPrep, message=F}
# -----------------------------------------------
# Prepare environment
# -----------------------------------------------
source(file = file.path("./Scripts","Setup","setup01_rEnvironment.R"))
load(file = file.path("./Scripts","s01.RData"))

```

Are the plots and tables also being written to file?
```{r}
params$print_results
```

#  Run 001

```{r, run001}

# Let's talk about how to best do this - a lot of this could/should be hidden into functions
# Feel free to add an example on how you usually do it

model_to_eval <- "001"

if(model_to_eval=="001"){
  
  # -----------------------
  #  Extract info about run from data base
  # -----------------------
  run_info  <- extract_nm(model_to_eval)
  
  # Note: this only works when outputting one file for now
  data_file <- run_info$output$ctl_out_files[str_detect(run_info$output$ctl_out_files, "tab")]
  descr     <- run_info$description

  # -----------------------
  #  Run summary
  # -----------------------
  nonmem2R::sumoR(run_info$input$ctl) 

  # # Or if you prefer the original sumo output:
  # system_cmd(paste0('sumo run', model_to_eval,".lst"), 
  #            dir=directories[["model_dir"]])
  
  # -----------------------
  #  Define output file names and title pages for evaluation
  # -----------------------
  graphics_filepath      <- file.path(directories[["res_base_model_dir"]], 
                                      paste0("evaluation_run", model_to_eval,".pdf"))
  ind_graphics_filepath  <- file.path(directories[["res_base_model_dir"]], 
                                      paste0("individual_fits_run", model_to_eval,".pdf"))
  
  eval_titlepage         <- paste0("Goodness-of-fit plots \n\n Run", model_to_eval, 
                                   "\n\n", descr)
  ind_eval_titlepage     <- paste0("Individual fits \n\n Run", model_to_eval, 
                                   "\n\n", descr)

  # -----------------------
  #  Read in output table and format
  # -----------------------
  tab <- read.csv(file = data_file, skip=1, sep = "", stringsAsFactors = F)
  tab <- r_data_structure(tab, # requires data.frame
                          data_spec = file.path(directories[["source_data_dir"]],
                                                dataspec_filename), 
                          nm_output = T)
  tab <- add_variables(tab)
  
  nm_conc_data <- tab %>% filter(EVID==0)
  nm_baseline <- nm_conc_data %>% filter(!duplicated(NMSEQSID))
  etas <- names(tab)[str_detect(names(tab),"ETA")]
  
  # -----------------------
  #  Graphical evaluation
  # -----------------------

  # ------ 1. GOF pooled data ----------
  model_evaluation <- list(gg_title_plot(eval_titlepage))
  
  model_evaluation$basic_gof <- 
    arrangeGrob( # grid.arrange(
      gg_obs_vs_pred(nm_conc_data, y=DV, x=PRED), 
      gg_obs_vs_pred(nm_conc_data, y=DV, x=IPRED), 
      gg_residuals(nm_conc_data, y=IWRES, x=TIME, absolute=T), 
      gg_residuals(nm_conc_data, y=CWRES, x=PRED), 
      nrow=2)
  
  model_evaluation$cwres <- 
    arrangeGrob( # grid.arrange(
      gg_residuals(nm_conc_data, y=CWRES, x=TIME), 
      gg_residuals(nm_conc_data, y=CWRES, x=TAPD), 
      gg_residuals(nm_conc_data, y=CWRES, x=PRED), 
      gg_qq_plot(nm_conc_data, sample=CWRES),
      nrow=2)
  
  model_evaluation$npde <- 
    arrangeGrob( # grid.arrange(
      gg_residuals(nm_conc_data, y=NPDE, x=TIME), 
      gg_residuals(nm_conc_data, y=NPDE, x=TAPD), 
      gg_residuals(nm_conc_data, y=NPDE, x=PRED), 
      gg_qq_plot(nm_conc_data, sample=NPDE),
      nrow=2)
  
  ## ------ 2. Distribution of individual parameters ----------
  model_evaluation$ind_parms <- 
    ggpairs(nm_baseline, columns = etas, 
            diag = list(continuous = "barDiag", na.rm=T), 
            upper = list(continuous = "blank"), 
            lower = list(continuous = "smooth"))
  
  # Print
  walk(model_evaluation, grob_draw)
  
  ## ------ 3. Individual fits ----------
  # Takes time to print, comment out the ones you don't need
  ind_nm_data_split <-
    nm_conc_data %>% 
    # OCC column needs to be factor for individual graphics
    mutate(OCC = factor(OCC, levels = sort(unique(OCC)))) %>% 
    ind_data_split(id="NMSEQSID")
  
  individual_fits <-
    list(gg_title_plot(ind_eval_titlepage))
  
  # TAPD
  individual_fits$t1 <- 
    gg_title_plot("Concentrations versus Time after dose")
  
  p <- vector("list",length(ind_nm_data_split))
  for(i in 1:length(ind_nm_data_split)){
    p[[i]] <- 
      gg_conc_time_ind(ind_nm_data_split[[i]],
                       x=TAPD, id=NMSEQSID, occ=OCC, 
                       facet_scales = NULL) + 
      labs(y=labs_conc, x=labs_TAPD)
  }
  individual_fits <- c(individual_fits, p)
  
  # TIME
  individual_fits$t3 <- gg_title_plot("Concentrations versus Time")
  
  p <- vector("list",length(ind_nm_data_split))
  for(i in 1:length(ind_nm_data_split)){
    p[[i]] <- 
      gg_conc_time_ind(ind_nm_data_split[[i]],
                       x=TIME, id=NMSEQSID, occ=OCC) + 
      labs(y=labs_conc, x=labs_TIME)
  }
  individual_fits <- c(individual_fits, p)

  # Print
  walk(individual_fits, grob_draw)
  
  if(params$print_results){
    # Print to file
    pdf(file = graphics_filepath, height=8.5, width=11)
    walk(model_evaluation, grob_draw)
    dev.off()
    
    pdf(file = ind_graphics_filepath, height=8.5, width=11)
    walk(individual_fits, grob_draw)
    dev.off()
  }
}
```

